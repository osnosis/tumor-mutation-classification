{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tumor Mutation Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we will analyze a dataset of tumor gene mutations and their associated risk category, which indicates the risk of malignancy for that mutation in the human condition. The dataset was hand-labeled and released by the team of clinical pathologists at Memorial Sloan Kettering in 2018 as part of the Kaggle competition 'Redefining Cancer'. <br>\n",
    "\n",
    "The problem I am attempting to solve is the classification of genetic tumor mutations into categories of risk. There are countless mutations that could occur in the genome of a tumor. Some of these mutations drive tumor growth, while others are neutral. Being able to classify a mutation into the correct category drives research and resources into the right places, allowing teams to target those specific mutations for personalized treatment of cancer. For example, if a mutation is categorized as a “driver”, we know that it contributes to tumor growth and that we can design a CRISPR editing tool to fix it, whereas if a mutation is categorized as a “passenger”, we know it doesn’t pose any risk and that it’s safe to leave alone. <br>\n",
    "\n",
    "This solution is valuable because it will automate the work of an entire team at the Memorial Sloan Kettering Cancer Center, a leading institution in the research and treatment of cancer. There is a team of clinical pathologists whose entire job consists of reading through peer-reviewed journal articles about tumor mutations to classify them into categories regarding their hazard level. The time it takes to read through thousands of papers could be reduced greatly by designing a program to classify tumor mutations based on their relevant clinical texts. This would allow more mutations to be classified and would free up the time of the clinical pathologists who could be better spending their time on issues that machine learning cannot yet solve, such as developing new pathology protocols or conducting hands-on research. <br>\n",
    "\n",
    "Once the program is developed, it could be made into a website or app where the user could upload one or more papers about an unclassified gene and get a classification back, perhaps even with a degree of certainty communicating how confident the model is in its recommendation. This could also be monitored by a professional who would double check the work before allowing any further decision to be made on it. <br>\n",
    "\n",
    "Our objective here is to fit the dataset into various machine learning models to predict the risk category while accounting for highly unbalanced classes. Several methods for text feature generation will be explored. We will then use the synthetic minority over-sampling technique (SMOTE) to resample the dataset to make the numbers of categories more even. The last step is to compare machine learning methods on our feature sets and tune our models to achieve maximum performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import io\n",
    "\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import csv\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import linear_model, decomposition, datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import log_loss, accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "from gensim import models\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "nlp = spacy.blank('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the Data\n",
    "\n",
    "The dataset comes from a Kaggle competition sponsored by the Memorial Sloan Kettering Cancer Center. The data includes a set of training and testing CSV’s with information on gene/mutations and the corresponding categories they fall into, labeled manually by the team of clinical pathologists. The labels have been anonymized such that the groups correspond to a number from 1-9 rather than a descriptive label. The data also includes the relevant clinical text for each gene/mutation pair as raw input for NLP feature generation. The lack of descriptive labels will shift the focus of this project to analyzing the effectiveness of different NLP techniques in distinguishing between different topics in the text, as opposed to using domain knowledge to evaluate whether the input features correspond to the output class. <br>\n",
    "\n",
    "We will now load in the data. The text needs to be cleaned of all non-legitimate words, such as figure references and parentheses. This will be accomplished using regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up packages for loading in data\n",
    "client = boto3.client('s3') #low-level functional API\n",
    "\n",
    "resource = boto3.resource('s3') #high-level object-oriented API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load in training data labels\n",
    "obj = client.get_object(Bucket='thinkful-capstone', Key='training_variants')\n",
    "stream = io.BytesIO(obj['Body'].read())\n",
    "training_variants = pd.read_csv(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID    Gene             Variation  Class\n",
      "0   0  FAM58A  Truncating Mutations      1\n",
      "1   1     CBL                 W802*      2\n",
      "2   2     CBL                 Q249E      2\n",
      "3   3     CBL                 N454D      3\n",
      "4   4     CBL                 L399V      4\n",
      "(3321, 4)\n"
     ]
    }
   ],
   "source": [
    "print(training_variants.head())\n",
    "print(training_variants.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID||Text\n",
      "0||Cyclin-dependent kinases (CDKs) regulate a variety of fundamental cellular processes. CDK10 stands out as one of the last orphan CDKs for which no activating cyclin has been identified and no kinase activity revealed. Previous work has shown that CDK10 silencing increases ETS2 (v-ets erythroblastosis virus E26 oncogene homolog 2)-driven activation of the MAPK pathway, which confers tamoxifen resistance to breast cancer cells. The precise mechanisms by which CDK10 modulates ETS2 activity, and more generally the functions of CDK10, remain elusive. Here we demonstrate that CDK10 is a cyclin-dependent kinase by identifying cyclin M as an activating cyclin. Cyclin M, an orphan cyclin, is the product of FAM58A, whose mutations cause STAR syndrome, a human developmental anomaly whose features include toe syndactyly, telecanthus, and anogenital and renal malformations. We show that STAR syndrome-associated cyclin M mutants are unable to interact with CDK10. Cyclin M silencing phenocopies CDK10 silencing in increasing c-Raf and in conferring tamoxifen resistance to breast cancer cells. CDK10/cyclin M phosphorylates ETS2 in vitro, and in cells it positively controls ETS2 degradation by the proteasome. ETS2 protein levels are increased in cells derived from a STAR patient, and this increase is attributable to decreased cyclin M levels. Altogether, our results reveal an additional regulatory mechanism for ETS2, which plays key roles in cancer and development. They also shed light on the molecular mechanisms underlying STAR syndrome.Cyclin-dependent kinases (CDKs) play a pivotal role in the control of a number of fundamental cellular processes (1). The human genome contains 21 genes encoding proteins that can be considered as members of the CDK family owing to their sequence similarity with bona fide CDKs, those known to be activated by cyclins (2). Although discovered almost 20 y ago (3, 4), CDK10 remains one of the two CDKs without an identified cyclin partner. This knowledge gap has largely impeded the exploration of its biological functions. CDK10 can act as a positive cell cycle regulator in some cells (5, 6) or as a tumor suppressor in others (7, 8). CDK10 interacts with the ETS2 (v-ets erythroblastosis virus E26 oncogene homolog 2) transcription factor and inhibits its transcriptional activity through an unknown mechanism (9). CDK10 knockdown derepresses ETS2, which increases the expression of the c-Raf protein kinase, activates the MAPK pathway, and induces resistance of MCF7 cells to tamoxifen (6).Here, we deorphanize CDK10 by identifying cyclin M, the product of FAM58A, as a binding partner. Mutations in this gene that predict absence or truncation of cyclin M are associated with STAR syndrome, whose features include toe syndactyly, telecanthus, and anogenital and renal malformations in heterozygous females (10). However, both the functions of cyclin M and the pathogenesis of STAR syndrome remain unknown. We show that a recombinant CDK10/cyclin M heterodimer is an active protein kinase that phosphorylates ETS2 in vitro. Cyclin M silencing phenocopies CDK10 silencing in increasing c-Raf and phospho-ERK expression levels and in inducing tamoxifen resistance in estrogen receptor (ER)+ breast cancer cells. We show that CDK10/cyclin M positively controls ETS2 degradation by the proteasome, through the phosphorylation of two neighboring serines. Finally, we detect an increased ETS2 expression level in cells derived from a STAR patient, and we demonstrate that it is attributable to the decreased cyclin M expression level observed in these cells.Previous SectionNext SectionResultsA yeast two-hybrid (Y2H) screen unveiled an interaction signal between CDK10 and a mouse protein whose C-terminal half presents a strong sequence homology with the human FAM58A gene product [whose proposed name is cyclin M (11)]. We thus performed Y2H mating assays to determine whether human CDK10 interacts with human cyclin M (Fig. 1 A–C). The longest CDK10 isoform (P1) expressed as a bait protein produced a strong interaction phenotype with full-length cyclin M (expressed as a prey protein) but no detectable phenotype with cyclin D1, p21 (CIP1), and Cdi1 (KAP), which are known binding partners of other CDKs (Fig. 1B). CDK1 and CDK3 also produced Y2H signals with cyclin M, albeit notably weaker than that observed with CDK10 (Fig. 1B). An interaction phenotype was also observed between full-length cyclin M and CDK10 proteins expressed as bait and prey, respectively (Fig. S1A). We then tested different isoforms of CDK10 and cyclin M originating from alternative gene splicing, and two truncated cyclin M proteins corresponding to the hypothetical products of two mutated FAM58A genes found in STAR syndrome patients (10). None of these shorter isoforms produced interaction phenotypes (Fig. 1 A and C and Fig. S1A).Fig. 1.In a new window Download PPTFig. 1.CDK10 and cyclin M form an interaction complex. (A) Schematic representation of the different protein isoforms analyzed by Y2H assays. Amino acid numbers are indicated. Black boxes indicate internal deletions. The red box indicates a differing amino acid sequence compared with CDK10 P1. (B) Y2H assay between a set of CDK proteins expressed as baits (in fusion to the LexA DNA binding domain) and CDK interacting proteins expressed as preys (in fusion to the B42 transcriptional activator). pEG202 and pJG4-5 are the empty bait and prey plasmids expressing LexA and B42, respectively. lacZ was used as a reporter gene, and blue yeast are indicative of a Y2H interaction phenotype. (C) Y2H assay between the different CDK10 and cyclin M isoforms. The amino-terminal region of ETS2, known to interact with CDK10 (9), was also assayed. (D) Western blot analysis of Myc-CDK10 (wt or kd) and CycM-V5-6His expression levels in transfected HEK293 cells. (E) Western blot analysis of Myc-CDK10 (wt or kd) immunoprecipitates obtained using the anti-Myc antibody. “Inputs” correspond to 10 μg total lysates obtained from HEK293 cells coexpressing Myc-CDK10 (wt or kd) and CycM-V5-6His. (F) Western blot analysis of immunoprecipitates obtained using the anti-CDK10 antibody or a control goat antibody, from human breast cancer MCF7 cells. “Input” corresponds to 30 μg MCF7 total cell lysates. The lower band of the doublet observed on the upper panel comigrates with the exogenously expressed untagged CDK10 and thus corresponds to endogenous CDK10. The upper band of the doublet corresponds to a nonspecific signal, as demonstrated by it insensitivity to either overexpression of CDK10 (as seen on the left lane) or silencing of CDK10 (Fig. S2B). Another experiment with a longer gel migration is shown in Fig. S1D.Next we examined the ability of CDK10 and cyclin M to interact when expressed in human cells (Fig. 1 D and E). We tested wild-type CDK10 (wt) and a kinase dead (kd) mutant bearing a D181A amino acid substitution that abolishes ATP binding (12). We expressed cyclin M-V5-6His and/or Myc-CDK10 (wt or kd) in a human embryonic kidney cell line (HEK293). The expression level of cyclin M-V5-6His was significantly increased upon coexpression with Myc-CDK10 (wt or kd) and, to a lesser extent, that of Myc-CDK10 (wt or kd) was increased upon coexpression with cyclin M-V5-6His (Fig. 1D). We then immunoprecipitated Myc-CDK10 proteins and detected the presence of cyclin M in the CDK10 (wt) and (kd) immunoprecipitates only when these proteins were coexpressed pair-wise (Fig. 1E). We confirmed these observations by detecting the presence of Myc-CDK10 in cyclin M-V5-6His immunoprecipitates (Fig. S1B). These experiments confirmed the lack of robust interaction between the CDK10.P2 isoform and cyclin M (Fig. S1C). To detect the interaction between endogenous proteins, we performed immunoprecipitations on nontransfected MCF7 cells derived from a human breast cancer. CDK10 and cyclin M antibodies detected their cognate endogenous proteins by Western blotting. We readily detected cyclin M in immunoprecipitates obtained with the CDK10 antibody but not with a control antibody (Fig. 1F). These results confirm the physical interaction between CDK10 and cyclin M in human cells.To unveil a hypothesized CDK10/cyclin M protein kinase activity, we produced GST-CDK10 and StrepII-cyclin M fusion proteins in insect cells, either individually or in combination. We observed that GST-CDK10 and StrepII-cyclin M copurified, thus confirming their interaction in yet another cellular model (Fig. 2A). We then performed in vitro kinase assays with purified proteins, using histone H1 as a generic substrate. Histone H1 phosphorylation was detected only from lysates of cells coexpressing GST-CDK10 and StrepII-cyclin M. No phosphorylation was detected when GST-CDK10 or StrepII-cyclin M were expressed alone, or when StrepII-cyclin M was coexpressed with GST-CDK10(kd) (Fig. 2A). Next we investigated whether ETS2, which is known to interact with CDK10 (9) (Fig. 1C), is a phosphorylation substrate of CDK10/cyclin M. We detected strong phosphorylation of ETS2 by the GST-CDK10/StrepII-cyclin M purified heterodimer, whereas no phosphorylation was detected using GST-CDK10 alone or GST-CDK10(kd)/StrepII-cyclin M heterodimer (Fig. 2B).Fig. 2.In a new window Download PPTFig. 2.CDK10 is a cyclin M-dependent protein kinase. (A) In vitro protein kinase assay on histone H1. Lysates from insect cells expressing different proteins were purified on a glutathione Sepharose matrix to capture GST-CDK10(wt or kd) fusion proteins alone, or in complex with STR-CycM fusion protein. Purified protein expression levels were analyzed by Western blots (Top and Upper Middle). The kinase activity was determined by autoradiography of histone H1, whose added amounts were visualized by Coomassie staining (Lower Middle and Bottom). (B) Same as in A, using purified recombinant 6His-ETS2 as a substrate.CDK10 silencing has been shown to increase ETS2-driven c-RAF transcription and to activate the MAPK \n"
     ]
    }
   ],
   "source": [
    "# Load in training data text articles\n",
    "obj = client.get_object(Bucket=\"thinkful-capstone\",Key=\"training_text\")\n",
    "raw_training_text = obj[\"Body\"].read()\n",
    "training_text = raw_training_text.decode('utf-8')\n",
    "print(training_text[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211296707\n",
      "205598350\n",
      "ID||Text\n",
      "0||Cyclin-dependent kinases (CDKs) regulate a variety of fundamental cellular processes. CDK10 stands out as one of the last orphan CDKs for which no activating cyclin has been identified and no kinase activity revealed. Previous work has shown that CDK10 silencing increases ETS2 (v-ets erythroblastosis virus E26 oncogene homolog 2)-driven activation of the MAPK pathway, which confers tamoxifen resistance to breast cancer cells. The precise mechanisms by which CDK10 modulates ETS2 activity, and more generally the functions of CDK10, remain elusive. Here we demonstrate that CDK10 is a cyclin-dependent kinase by identifying cyclin M as an activating cyclin. Cyclin M, an orphan cyclin, is the product of FAM58A, whose mutations cause STAR syndrome, a human developmental anomaly whose features include toe syndactyly, telecanthus, and anogenital and renal malformations. We show that STAR syndrome-associated cyclin M mutants are unable to interact with CDK10. Cyclin M silencing phenocopies CDK10 silencing in increasing c-Raf and in conferring tamoxifen resistance to breast cancer cells. CDK10/cyclin M phosphorylates ETS2 in vitro, and in cells it positively controls ETS2 degradation by the proteasome. ETS2 protein levels are increased in cells derived from a STAR patient, and this increase is attributable to decreased cyclin M levels. Altogether, our results reveal an additional regulatory mechanism for ETS2, which plays key roles in cancer and development. They also shed light on the molecular mechanisms underlying STAR syndrome.Cyclin-dependent kinases (CDKs) play a pivotal role in the control of a number of fundamental cellular processes. The human genome contains 21 genes encoding proteins that can be considered as members of the CDK family owing to their sequence similarity with bona fide CDKs, those known to be activated by cyclins. Although discovered almost 20 y ago, CDK10 remains one of the two CDKs without an identified cyclin partner. This knowledge gap has largely impeded the exploration of its biological functions. CDK10 can act as a positive cell cycle regulator in some cells or as a tumor suppressor in others. CDK10 interacts with the ETS2 (v-ets erythroblastosis virus E26 oncogene homolog 2) transcription factor and inhibits its transcriptional activity through an unknown mechanism. CDK10 knockdown derepresses ETS2, which increases the expression of the c-Raf protein kinase, activates the MAPK pathway, and induces resistance of MCF7 cells to tamoxifen.Here, we deorphanize CDK10 by identifying cyclin M, the product of FAM58A, as a binding partner. Mutations in this gene that predict absence or truncation of cyclin M are associated with STAR syndrome, whose features include toe syndactyly, telecanthus, and anogenital and renal malformations in heterozygous females. However, both the functions of cyclin M and the pathogenesis of STAR syndrome remain unknown. We show that a recombinant CDK10/cyclin M heterodimer is an active protein kinase that phosphorylates ETS2 in vitro. Cyclin M silencing phenocopies CDK10 silencing in increasing c-Raf and phospho-ERK expression levels and in inducing tamoxifen resistance in estrogen receptor (ER)+ breast cancer cells. We show that CDK10/cyclin M positively controls ETS2 degradation by the proteasome, through the phosphorylation of two neighboring serines. Finally, we detect an increased ETS2 expression level in cells derived from a STAR patient, and we demonstrate that it is attributable to the decreased cyclin M expression level observed in these cells.Previous SectionNext SectionResultsA yeast two-hybrid (Y2H) screen unveiled an interaction signal between CDK10 and a mouse protein whose C-terminal half presents a strong sequence homology with the human FAM58A gene product [whose proposed name is cyclin M]. We thus performed Y2H mating assays to determine whether human CDK10 interacts with human cyclin M. The longest CDK10 isoform (P1) expressed as a bait protein produced a\n"
     ]
    }
   ],
   "source": [
    "# Eliminate references and abbreviations within parentheses\n",
    "print(len(training_text))\n",
    "training_text = re.sub(' \\(Fig \\d+.+?\\)', '', training_text)\n",
    "training_text = re.sub(' \\(Fig\\. \\d+.+?\\)', '', training_text)\n",
    "training_text = re.sub(' \\(\\d.*?\\)', '', training_text)\n",
    "training_text = re.sub(' \\([A-Z]\\)', '', training_text)\n",
    "print(len(training_text))\n",
    "print(training_text[:4000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3321\n"
     ]
    }
   ],
   "source": [
    "# Split text file into list of documents\n",
    "training_list = training_text.split('||')\n",
    "training_list = training_list[2:]\n",
    "print(len(training_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID    Gene             Variation  Class  \\\n",
      "0   0  FAM58A  Truncating Mutations      1   \n",
      "1   1     CBL                 W802*      2   \n",
      "2   2     CBL                 Q249E      2   \n",
      "3   3     CBL                 N454D      3   \n",
      "4   4     CBL                 L399V      4   \n",
      "\n",
      "                                                text  \n",
      "0  Cyclin-dependent kinases (CDKs) regulate a var...  \n",
      "1   Abstract Background  Non-small cell lung canc...  \n",
      "2   Abstract Background  Non-small cell lung canc...  \n",
      "3  Recent evidence has demonstrated that acquired...  \n",
      "4  Oncogenic mutations in the monomeric Casitas B...  \n",
      "(3321, 5)\n"
     ]
    }
   ],
   "source": [
    "# Load training text list into dataframe\n",
    "texts_df = pd.DataFrame(training_list, columns = ['text'])\n",
    "\n",
    "# Merge text dataframe with labels dataframe\n",
    "train = pd.concat([training_variants, texts_df], axis=1)\n",
    "print(train.head())\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Temporary cell to reduce data size for experimentation\n",
    "# train = train[:400]\n",
    "# print(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is loaded into a dataframe, let's do some preliminary data exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7    953\n",
      "4    686\n",
      "1    568\n",
      "2    452\n",
      "6    275\n",
      "5    242\n",
      "3     89\n",
      "9     37\n",
      "8     19\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 3321 total datapoints to work with, and it looks like we are dealing with significant class imbalance. Class 7 has 953 datapoints, while Class 8 has only 19. We will have to address this class imbalance with our experiment design. Additionally, the labels have been anonymized, which means we cannot draw any insight about what these classes might signify. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Design\n",
    "\n",
    "The prevalence of class imbalance has serious implications for our analysis. First and foremost, we must establish our scoring metric. The purpose here is to use the relevant clinical texts to predict the mutation category for each gene/mutation pair. While we want the predictions to be as accurate as possible, simple classification accuracy is not a representative way to judge models that are built on class imbalance, as they may achieve high accuracy by simply predicting the most common class every time. <br>\n",
    "\n",
    "Given that we are working with a multi-label classifier, the most appropriate scoring metric is log loss. Log loss is a commonly used evaluation metric that quantifies the accuracy of a classifier by penalising false classifications, and heavily penalises classifiers that are confident about an incorrect classification. It is a more nuanced scoring metric than traditional accuracy because it takes into account the uncertainty of the model's predictions instead of just giving a yes or no. <br>\n",
    "\n",
    "When feeding our data into the predictive models, the classifier must assign a probability to each class. The prediction is awarded to the class with the highest probability, and these resulting probabilities are multiplied by one another to get the overall probability that all of those outcomes occurred together.  As each event gets multiplied in, the final number gets smaller and smaller. So, we take the log to put the number in a more accessible range, resulting in a negative number. The number is then multiplied by -1 to maintain the convention that a lower loss score is better. We will also look at the precision and recall via the F1 score. Though these are not optimized for multi-label classification, they help to put the log loss score into context. <br>\n",
    "\n",
    "Source: https://datawookie.netlify.com/blog/2015/12/making-sense-of-logarithmic-loss/, https://www.kaggle.com/dansbecker/what-is-log-loss\n",
    "\n",
    "I will use various methods of feature generation including classic NLP techniques such as bag-of-words, tf-idf, and n-grams. They will then be subjected to various machine learning classifiers. All machine learning models will be run with a variety of hyperparameters on a variety of datasets, and the permutation with the best log-loss score will be chosen to move forward. <br>\n",
    "\n",
    "We will also try to oversample the lesser-represented categories and apply our machine learning models on the oversampled datasets. Oversampling can be achieved by generating duplicate datapoints or by generating new synthetic datapoints via SMOTE, the Synthetic Minority Oversampling Technique, a feature of the imbalanced learn package. Although undersampling has proven effective for high-dimensional data, we will not try undersampling at this time as we only have a few thousand datapoints and removing some would likely eliminate too much information. <br>\n",
    "\n",
    "We will experiment with dimensionality reduction, as this can significantly reduce the storage and computation requirements of our model. We will experiment with Truncated Singular Value Decomposition, a method of dimensionality reduction that is known to work well with sparse data. This transformation is termed Latent Semantic Analysis, a technique that is known to combat polysemy and synonymy. <br>\n",
    "\n",
    "Source: http://scikit-learn.org/stable/modules/decomposition.html#truncated-singular-value-decomposition-and-latent-semantic-analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is relatively clean already, and contains no NaN values. It needs to be tokenized so it can be processed into readable pieces of data. We will use spaCy to tokenize the data and create a new column with a list of the tokens for each row. Furthermore, we will convert all tokens that are not stop words or punctuation to lemmas to reduce the noise from unnecessary words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'off', 's', 'ain', \"needn't\", 'couldn', 'all', 'her', 'has', 'of', 'ma', 'before', 'during', 'over', 'which', 're', 'yours', \"don't\", 'our', 'them', 'y', 'each', 'that', 'wasn', \"mustn't\", 'very', 'not', 'from', 'up', 'when', 'd', 'until', 'now', 'below', 'she', 'doing', 'down', 'am', 'hadn', 'wouldn', \"won't\", 'herself', 'the', 'me', \"couldn't\", 'between', 'on', \"you're\", 'myself', 'haven', 'won', 'through', 'only', \"you've\", 'then', 'no', 'having', 'don', 'what', 'being', 'yourselves', 'shouldn', 'him', 'than', 'where', 'll', 'at', 'own', 'if', \"didn't\", 'were', 'while', 'most', 'who', \"hadn't\", 'an', \"wouldn't\", 'for', 'under', 'its', 'doesn', \"isn't\", 'is', 'and', 'mightn', 'any', 'against', \"hasn't\", 'because', 'to', 've', 'it', 'mustn', 'shan', 'so', 'they', 'isn', 'their', 'whom', \"doesn't\", 'further', \"shouldn't\", 'have', 'by', 'needn', \"should've\", 'does', 'or', 'after', \"aren't\", 'did', 'there', 'you', 'had', \"you'll\", 'too', 'as', 'will', 'those', 'be', 'about', 'nor', 'few', \"weren't\", 'themselves', 'such', 'some', \"shan't\", \"wasn't\", 'once', 'weren', 'ours', 'been', \"that'll\", 't', \"you'd\", \"haven't\", 'o', 'do', 'are', 'but', 'above', 'ourselves', 'these', 'was', 'more', 'aren', 'itself', 'theirs', 'other', 'same', 'yourself', 'this', 'with', 'i', 'my', 'just', 'a', 'his', 'here', 'both', \"mightn't\", 'we', 'your', 'should', 'again', 'can', 'into', 'in', 'm', 'hasn', \"it's\", 'why', \"she's\", 'how', 'out', 'didn', 'himself', 'he', 'hers'}\n"
     ]
    }
   ],
   "source": [
    "# Define stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beginning lemmatization\n",
      "   ID    Gene             Variation  Class  \\\n",
      "0   0  FAM58A  Truncating Mutations      1   \n",
      "1   1     CBL                 W802*      2   \n",
      "2   2     CBL                 Q249E      2   \n",
      "3   3     CBL                 N454D      3   \n",
      "4   4     CBL                 L399V      4   \n",
      "\n",
      "                                                text  \\\n",
      "0  Cyclin-dependent kinases (CDKs) regulate a var...   \n",
      "1   Abstract Background  Non-small cell lung canc...   \n",
      "2   Abstract Background  Non-small cell lung canc...   \n",
      "3  Recent evidence has demonstrated that acquired...   \n",
      "4  Oncogenic mutations in the monomeric Casitas B...   \n",
      "\n",
      "                                        spacy_tokens  \\\n",
      "0  (Cyclin, -, dependent, kinases, (, CDKs, ), re...   \n",
      "1  ( , Abstract, Background,  , Non, -, small, ce...   \n",
      "2  ( , Abstract, Background,  , Non, -, small, ce...   \n",
      "3  (Recent, evidence, has, demonstrated, that, ac...   \n",
      "4  (Oncogenic, mutations, in, the, monomeric, Cas...   \n",
      "\n",
      "                                              lemmas  \n",
      "0  [cyclin, dependent, kinase, cdks, regulate, va...  \n",
      "1  [abstract, background, non, small, cell, lung,...  \n",
      "2  [abstract, background, non, small, cell, lung,...  \n",
      "3  [recent, evidence, demonstrate, acquire, unipa...  \n",
      "4  [oncogenic, mutation, monomeric, casitas, b, l...  \n"
     ]
    }
   ],
   "source": [
    "# Convert documents to spaCy tokens\n",
    "train['spacy_tokens'] = train['text'].apply(lambda x: nlp(x))\n",
    "\n",
    "# Convert spaCy tokens to lemmas\n",
    "def lemmatize(x):\n",
    "    intermediate_lemmas = [token.lemma_.lower() for token in x\n",
    "            if not token.is_punct]\n",
    "    return [lemma for lemma in intermediate_lemmas\n",
    "           if lemma not in stop_words\n",
    "           and lemma != \"-PRON-\"\n",
    "           and lemma != \" \"\n",
    "           ]\n",
    "\n",
    "train['lemmas'] = train['spacy_tokens'].apply(lambda x: lemmatize(x))\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our lemmatized documents, we must convert them back into strings and create a list of all the string-converted documents to feed to our feature generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert each lemma/token document to a lemma/string document and make a list of them\n",
    "joined_lemma_documents = [\n",
    "    ' '.join([str(word) for word in text])\n",
    "    for text in train['lemmas'].values.tolist()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update training dataframe with lemmatized documents\n",
    "train['lemmatized'] = joined_lemma_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reserve 20% of training dataset for external validation\n",
    "train, test = train_test_split(train,\n",
    "                                test_size = 0.2,\n",
    "                                random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to reduce unnecessary input to the vectorizer, we want to cut each document to its most important features. But how will we know how many features to keep? First, we will create a dictionary of all the words in the corpora and their frequencies using Counter. Then we will graph the words by frequency to see how many words make up the majority of our corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create list of 500 most common words per training set to reduce features in testing set\n",
    "# Create a dictionary of words and frequencies\n",
    "counter = Counter()\n",
    "\n",
    "# Iterate through each training document, split into words and add words/frequencies to Counter\n",
    "for document in train['lemmatized']:\n",
    "    words = document.split(' ')\n",
    "    counter.update(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['mutation', 528768], ['cell', 482300]]\n"
     ]
    }
   ],
   "source": [
    "# Convert word/frequency dictionary to list sorted by frequency\n",
    "word_frequencies = sorted(\n",
    "                        [[key, value] for key, value in counter.items()],\n",
    "                        key = lambda x: x[1],\n",
    "                        reverse = True\n",
    "                        )\n",
    "\n",
    "print(word_frequencies[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of terms: 205136\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEKCAYAAADEovgeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsRd/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f13e0a3bc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot term frequency, trim list to 2000 most common words for easier visualization\n",
    "print('Total number of terms:', len(word_frequencies))\n",
    "trim_length = 2000\n",
    "trim_frequencies = word_frequencies[:trim_length]\n",
    "frequency_X = list(range(len(trim_frequencies)))\n",
    "frequency_Y = [frequency_pair[1] for frequency_pair in trim_frequencies]\n",
    "plt.plot(frequency_X, frequency_Y)\n",
    "plt.xlabel('Rank of Frequency')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the term frequencies drop off after the first 250 words. After 250, the term frequencies become very sparse and will likely add little value to our model. Still, we will keep the 500 most common words for input to our vectorizers to ensure that we are not losing any potentially valuable features. We will utilize the 'max_feature' hyperparameter in the tf-idf and count vectorizer (bag-of-words), which will allow us to reduce the dataset to these 500 most common words in one simple step. <br>\n",
    "\n",
    "However, when we run our external validation set (reserved 20%) we cannot verify it unless our validation set has the same features as our training set. For this reason, we will extract the 500 most common words from our training set and reduce our validation documents to these 500 words. While this significantly changes our testing data, it is the only way to evaluate the legitimacy of our chosen model. This is a common problem in natural language processing, and typically handled by either ignoring all unseen words in the testing document or lumping them into a single 'unknown' type. In this case, we will ignore the unseen words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create list of 500 most common words per training document\n",
    "common_words_500 = [frequency_pair[0] for frequency_pair in word_frequencies[:500]]\n",
    "\n",
    "reduced_documents = []\n",
    "# Reducing test documents to 500 most common words per training set\n",
    "for document in test['lemmatized'].values.tolist():\n",
    "    words = document.split(' ')\n",
    "    reduced_document = [word for word in words\n",
    "                       if word in common_words_500]\n",
    "    reduced_document = ' '.join(reduced_document)\n",
    "    reduced_documents.append(reduced_document)\n",
    "    \n",
    "test['lemmas'] = reduced_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Export training/testing dataframes to csv\n",
    "train.to_csv('lemmatized_train.csv')\n",
    "test.to_csv('lemmatized_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search in Pipeline: Feature Generation, Dimensionality Reduction, Oversampling and Machine Learning\n",
    "\n",
    "In this section, we will create a pipeline that iterates through several different parameters and classifier types. For feature generation, we will attempt both tf-idf vectorization and bag-of-words vectorization, which will convert our list of strings into sparse dataframes. Beyond using singular words (or lemmas) as features for classification, we can also use groupings of words that appear together, as they may convey more contextual meaning than each word isolated by itself. We will use the native 'ngram_range' hyperparameter to broaden our dataset to include common bigrams as well. We will run bag-of-words and tf-idf with unigrams and bigrams, as groupings larger than 2 words in a dataset this small would likely create unnecessary noise without adding any insight. <br>\n",
    "\n",
    "Bag-of-words is a simplistic representation of text that considers only term frequency and assumes that position doesn't matter. It quantifies the content by looking at each document as a ’bag’ of words, while disregarding context and grammar. The idea is that documents with similar vocabularies will have similar content. <br>\n",
    "\n",
    "Tf-idf is a more nuanced representation of text that considers the term frequency as well the inverse document frequency, which gives more information about how significant each word is. For example, a common word such as \"the\" may score high in term frequency, but having high term frequency in every document would diminish its meaning and thus its tf-idf score. <br>\n",
    "\n",
    "Both bag-of-words and tf-idf have several parameters that can be optimized through the grid search. For the sake of brevity, we will only tune the 'max_df' and 'min_df', which represent the maximum and minimum number of times a term should appear in any given document (integer), or the proportion of that word against all words in the document (decimal). <br>\n",
    "\n",
    "As mentioned before, we will also implement oversampling via SMOTE to combat the class imbalance. For each time the algorithm runs, one of the K closest minority class neighbors is chosen and a new minority instance is synthesized somewhere between the minority instance and that neighbor. We will use the default value of K=5 neighbors. In an effort to reduce computational complexity, we will hold off on tuning other parameters. The minority classes will be resampled until they match the size of the majority class. Two methods of SMOTE will be evaluated, 'regular' and 'borderline1'.\n",
    "\n",
    "Finally, we will apply several different machine learning models and evaluate their performance using cross-validation with log-loss scoring. First, we will try logistic regression since it is quick and easy to run. We will also try random forests, as ensemble models tend to be robust against overfitting. Random forest language models have been shown to generalize well to unseen data. The random forest has several parameters that will be tuned with the high dimensionality of the dataset in mind. XGBoost is another ensemble model that has demonstrated strong predictive power. Through gradient boosting, XGBoost identifies the errors of prior models and uses them to inform future models. XGBoost is known to have high model performance and relatively low time/storage complexity. \n",
    "\n",
    "Source: http://www.aclweb.org/anthology/W04-3242\n",
    "\n",
    "\n",
    "We will also try Naive Bayes with  multinomial regression, as this is a commonly used technique for NLP problems. The multinomial Naive Bayes model 'naively' assumes that all features are independent from one another. In reality, the conditional independence assumption does not hold for text data, but the model is still able to produce fairly reliable predictions. Naive Bayes is particularly useful when there are many equally important features that jointly contribute to the classification decision. It is also somewhat robust to noisy features, and very quick to run. We will use Naive Bayes with a multinomial distribution, which works under the bag-of-words assumption that position doesn't matter. The sklearn documentation states that \"the multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g. word counts for text classification). The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work.\" This means that we can effectively use it with both bag-of-words and tf-idf generated datasets.\n",
    "\n",
    "Source: https://nlp.stanford.edu/IR-book/html/htmledition/properties-of-naive-bayes-1.html, https://web.stanford.edu/class/cs124/lec/naivebayes.pdf, http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\n",
    "\n",
    "Given it’s reputation for success, I hypothesize that XGBoost will perform the best. It is a newer algorithm designed specifically to maximize model performance, and many Kaggle competitions have been won using XGBoost. I predict that tf-idf will outperform bag-of-words due to its nuanced representatation of text, and that oversampling will help our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load in training dataframe\n",
    "train = pd.read_csv('~/tumor-mutation-classification/lemmatized_train.csv')\n",
    "X = train['lemmatized']\n",
    "Y = train['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up pipeline\n",
    "pipe = Pipeline(steps=[\n",
    "    ('feat_gen', TfidfVectorizer()), #CountVectorizer() not named here but included below in param_grid\n",
    "    ('oversample', SMOTE(k_neighbors = 5)),\n",
    "    ('machine', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Feature generation parameters\n",
    "maxdf = [0.25, 0.5, 0.75]\n",
    "mindf = [0.01, 0.05, 0.1]\n",
    "# Oversampling parameters\n",
    "smote_kind = ['regular','borderline1']\n",
    "# Machine learning model parameters \n",
    "C_values = [1e-3, 1e-1, 1, 100]\n",
    "\n",
    "param_grid = [\n",
    "    # Tfidf permutations first\n",
    "    # With and without oversampling, ngrams\n",
    "    {\n",
    "        'feat_gen': [TfidfVectorizer(max_features = 500)],\n",
    "        'feat_gen__max_df': maxdf,\n",
    "        'feat_gen__min_df': mindf,\n",
    "        'oversample__kind': smote_kind,\n",
    "        'machine': [LogisticRegression(random_state=1)],\n",
    "        'machine__C': C_values\n",
    "    },\n",
    "    {\n",
    "        'feat_gen': [TfidfVectorizer(max_features = 500)],\n",
    "        'feat_gen__max_df': maxdf,\n",
    "        'feat_gen__min_df': mindf,\n",
    "        'machine': [LogisticRegression(random_state=1)],\n",
    "        'machine__C': C_values\n",
    "    },\n",
    "    # Bag of words permutations next\n",
    "    # With and without oversampling, ngrams\n",
    "    {\n",
    "        'feat_gen': [CountVectorizer(max_features = 500)],\n",
    "        'feat_gen__max_df': maxdf,\n",
    "        'feat_gen__min_df': mindf,\n",
    "        'oversample__kind': smote_kind,\n",
    "        'machine': [LogisticRegression(random_state=1)],\n",
    "        'machine__C': C_values\n",
    "    },\n",
    "    {\n",
    "        'feat_gen': [CountVectorizer(max_features = 500)],\n",
    "        'feat_gen__max_df': maxdf,\n",
    "        'feat_gen__min_df': mindf,\n",
    "        'machine': [LogisticRegression(random_state=1)],\n",
    "        'machine__C': C_values\n",
    "    }\n",
    "]\n",
    "\n",
    "# Run grid search with cross validation\n",
    "grid = GridSearchCVProgressBar(pipe, cv=3, param_grid=param_grid, verbose=2, scoring = 'log_loss')\n",
    "grid.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have run the grid search, we will export our findings to a csv so that we can access them without having to run the expensive grid search every time. We will create a function that can be re-used throughout the notebook to export all the grid search findings from each machine learning model type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sort and export all results for grid search to csv\n",
    "def export_gridsearch_to_csv(gs_clf, export_file):\n",
    "    with open(export_file, 'w') as outfile:\n",
    "        csvwriter = csv.writer(outfile, delimiter=',')\n",
    "\n",
    "        # Create the header using the parameter names \n",
    "        header = [\"mean\",\"std\", \"params\"]\n",
    "\n",
    "        csvwriter.writerow(header)\n",
    "\n",
    "        sorted_by_score = sorted(gs_clf.grid_scores_, key = itemgetter(1), reverse=True)\n",
    "\n",
    "        for config in sorted_by_score:\n",
    "            # Get mean and standard deviation\n",
    "            mean = np.abs(config[1])\n",
    "            std = np.std(config[2])\n",
    "            row = [mean,std, str(config[0])]\n",
    "\n",
    "            csvwriter.writerow(row)\n",
    "\n",
    "filename = datetime.datetime.utcnow().strftime('logistic_gridresults_%Y%m%d_%H:%M.csv')       \n",
    "export_gridsearch_to_csv(grid, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up pipeline\n",
    "pipe = Pipeline(steps=[\n",
    "    ('feat_gen', TfidfVectorizer()),\n",
    "    ('oversample', SMOTE(k_neighbors = 5)),\n",
    "    ('machine', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Feature generation parameters\n",
    "maxdf = [0.25, 0.5, 0.75]\n",
    "mindf = [0.01, 0.05, 0.1]\n",
    "# Oversampling parameters\n",
    "smote_kind = ['regular','borderline1']\n",
    "# Machine learning model parameters \n",
    "rf_max_depth = [30, 60, 100]\n",
    "rf_min_samples_split = [430]\t# 430 represents 5% of the dataset after oversampling\n",
    "rf_n_estimators = [10]\n",
    "\n",
    "param_grid = [\n",
    "    # Tfidf permutations with and without n-grams\n",
    "    # Removed permutations with CountVectorizer after logistic regression demonstrated poor log loss scores\n",
    "    # Removed permutations without oversampling after logistic regression demonstrated poor log loss scores\n",
    "    {\n",
    "        'feat_gen': [TfidfVectorizer(max_features = 500)],\n",
    "        'feat_gen__max_df': maxdf,\n",
    "        'feat_gen__min_df': mindf,\n",
    "        'oversample__kind': smote_kind,\n",
    "        'machine': [RandomForestClassifier(random_state = 1)],\n",
    "        'machine__max_depth': rf_max_depth,\n",
    "        'machine__min_samples_split': rf_min_samples_split,\n",
    "        'machine__n_estimators': rf_n_estimators\n",
    "    },\n",
    "        {\n",
    "        'feat_gen': [TfidfVectorizer(max_features = 500, ngram_range=(2,2))],\n",
    "        'feat_gen__max_df': maxdf,\n",
    "        'feat_gen__min_df': mindf,\n",
    "        'oversample__kind': smote_kind,\n",
    "        'machine': [RandomForestClassifier(random_state = 1)],\n",
    "        'machine__max_depth': rf_max_depth,\n",
    "        'machine__min_samples_split': rf_min_samples_split,\n",
    "        'machine__n_estimators': rf_n_estimators\n",
    "    }\n",
    "]\n",
    "# Run grid search with cross validation\n",
    "grid = GridSearchCVProgressBar(pipe, cv=3, param_grid=param_grid, verbose=2, scoring = 'log_loss')\n",
    "grid.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = datetime.datetime.utcnow().strftime('rf_gridresults_%Y%m%d_%H:%M.csv')       \n",
    "export_gridsearch_to_csv(grid, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up pipeline\n",
    "pipe = Pipeline(steps=[\n",
    "    ('feat_gen', TfidfVectorizer()),\n",
    "    ('oversample', SMOTE(k_neighbors = 5)),\n",
    "    ('machine', XGBClassifier())\n",
    "])\n",
    "\n",
    "# Feature generation parameters\n",
    "# max_df and min_df values reduced to best-performing values from logistic/random forest grid search\n",
    "maxdf = [0.75]\n",
    "mindf = [0.05]\n",
    "# Oversampling parameters\n",
    "smote_kind = ['regular','borderline1']\n",
    "# Machine learning model parameters \n",
    "xg_booster = ['gbtree','gblinear']\n",
    "xg_learning_rate = [0.01, 0.1, 0.3]\n",
    "xg_max_depth = [30, 60, 100]\n",
    "xg_subsample = [0.5, 1]\n",
    "\n",
    "param_grid = [\n",
    "# Tfidf permutations with and without n-grams\n",
    "# Removed permutations with CountVectorizer after logistic regression demonstrated poor log loss scores\n",
    "# Removed permutations without oversampling after logistic regression demonstrated poor log loss scores\n",
    "    {\n",
    "        'feat_gen': [TfidfVectorizer(max_features = 500)],\n",
    "        'feat_gen__max_df': maxdf,\n",
    "        'feat_gen__min_df': mindf,\n",
    "        'oversample__kind': smote_kind,\n",
    "        'machine': [XGBClassifier(random_state = 1)],\n",
    "        'machine__booster': xg_booster,\n",
    "        'machine__learning_rate': xg_learning_rate,\n",
    "        'machine__max_depth': xg_max_depth,\n",
    "        'machine__subsample': xg_subsample\n",
    "    },\n",
    "        {\n",
    "        'feat_gen': [TfidfVectorizer(max_features = 500, ngram_range=(2,2))],\n",
    "        'feat_gen__max_df': maxdf,\n",
    "        'feat_gen__min_df': mindf,\n",
    "        'oversample__kind': smote_kind,\n",
    "        'machine__booster': xg_booster,\n",
    "        'machine__learning_rate': xg_learning_rate,\n",
    "        'machine__max_depth': xg_max_depth,\n",
    "        'machine__subsample': xg_subsample\n",
    "    }\n",
    "]\n",
    "# Run grid search with cross validation\n",
    "grid = GridSearchCVProgressBar(pipe, cv=3, param_grid=param_grid, verbose=2, scoring = 'log_loss')\n",
    "grid.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = datetime.datetime.utcnow().strftime('xg_gridresults_%Y%m%d_%H:%M.csv')       \n",
    "export_gridsearch_to_csv(grid, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Pipeline (Multinomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up pipeline\n",
    "pipe = Pipeline(steps=[\n",
    "    ('feat_gen', TfidfVectorizer()),\n",
    "    ('oversample', SMOTE(k_neighbors = 5)),\n",
    "    ('machine', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Feature generation parameters\n",
    "# max_df and min_df values reduced to best-performing values from logistic/random forest grid search\n",
    "maxdf = [0.75]\n",
    "mindf = [0.05]\n",
    "# Oversampling parameters\n",
    "smote_kind = ['regular','borderline1']\n",
    "# Default machine learning model parameters \n",
    "\n",
    "param_grid = [\n",
    "# Tfidf permutations with and without n-grams\n",
    "# Removed permutations with CountVectorizer after logistic regression demonstrated poor log loss scores\n",
    "# Removed permutations without oversampling after logistic regression demonstrated poor log loss scores\n",
    "    {\n",
    "        'feat_gen': [TfidfVectorizer(max_features = 500)],\n",
    "        'feat_gen__max_df': maxdf,\n",
    "        'feat_gen__min_df': mindf,\n",
    "        'oversample__kind': smote_kind,\n",
    "        'machine': [MultinomialNB()],\n",
    "    },\n",
    "        {\n",
    "        'feat_gen': [TfidfVectorizer(max_features = 500, ngram_range=(2,2))],\n",
    "        'feat_gen__max_df': maxdf,\n",
    "        'feat_gen__min_df': mindf,\n",
    "        'oversample__kind': smote_kind,\n",
    "        'machine': [MultinomialNB()],\n",
    "    }\n",
    "]\n",
    "# Run grid search with cross validation\n",
    "grid = GridSearchCVProgressBar(pipe, cv=3, param_grid=param_grid, verbose=2, scoring = 'log_loss')\n",
    "grid.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = datetime.datetime.utcnow().strftime('nb_gridresults_%Y%m%d_%H:%M.csv')       \n",
    "export_gridsearch_to_csv(grid, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating grid search results\n",
    "\n",
    "Now that all of our preliminary pipelines have been run, we can take a look at the resulting log loss scores and judge which machine learning model was the most effective on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load in results dataframes from csv files\n",
    "logistic_results = pd.read_csv('scripts/logistic_gridresults_20180629_00:02.csv')\n",
    "nb_results = pd.read_csv('scripts/nb_gridresults_20180703_18:04.csv')\n",
    "rf_results = pd.read_csv('scripts/rf_gridresults_20180701_22:50.csv')\n",
    "xg_results = pd.read_csv('scripts/xg_gridresults_20180630_17:46.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>log loss mean</th>\n",
       "      <th>std</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random forest</td>\n",
       "      <td>1.832495</td>\n",
       "      <td>0.011121</td>\n",
       "      <td>{'feat_gen': TfidfVectorizer(analyzer='word', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>naive bayes</td>\n",
       "      <td>1.839022</td>\n",
       "      <td>0.044531</td>\n",
       "      <td>{'feat_gen': TfidfVectorizer(analyzer='word', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>1.863806</td>\n",
       "      <td>0.055248</td>\n",
       "      <td>{'feat_gen': TfidfVectorizer(analyzer='word', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic</td>\n",
       "      <td>1.888993</td>\n",
       "      <td>0.061842</td>\n",
       "      <td>{'feat_gen': TfidfVectorizer(analyzer='word', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      classifier  log loss mean       std  \\\n",
       "2  random forest       1.832495  0.011121   \n",
       "1    naive bayes       1.839022  0.044531   \n",
       "3        xgboost       1.863806  0.055248   \n",
       "0       logistic       1.888993  0.061842   \n",
       "\n",
       "                                              params  \n",
       "2  {'feat_gen': TfidfVectorizer(analyzer='word', ...  \n",
       "1  {'feat_gen': TfidfVectorizer(analyzer='word', ...  \n",
       "3  {'feat_gen': TfidfVectorizer(analyzer='word', ...  \n",
       "0  {'feat_gen': TfidfVectorizer(analyzer='word', ...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Isolate the top performing model from each dataframe\n",
    "best_logistic = pd.Series(['logistic', logistic_results['mean'][0], logistic_results['std'][0], logistic_results['params'][0]])\n",
    "best_nb = pd.Series(['naive bayes', nb_results['mean'][0], nb_results['std'][0], nb_results['params'][0]])\n",
    "best_rf = pd.Series(['random forest', rf_results['mean'][0], rf_results['std'][0], rf_results['params'][0]])\n",
    "best_xg = pd.Series(['xgboost', xg_results['mean'][0], xg_results['std'][0], xg_results['params'][0]])\n",
    "best_gridresults = pd.DataFrame().append([best_logistic, best_nb, best_rf, best_xg], ignore_index=True)\n",
    "best_gridresults.columns = ['classifier','log loss mean','std','params']\n",
    "best_gridresults = best_gridresults.sort_values(by=['log loss mean'], ascending=True)\n",
    "best_gridresults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a mean log loss score of 1.83, random forest was the best-performing classifier on the training dataset. It also had the lowest standard deviation which means it was most consistent across the cross-validated folds. Decision trees/random forests are known to perform well on imbalanced datasets, which we are currently working with. Naive Bayes was the next best classifer at 1.84, with xgboost and logistic behind. Although random forest has the lowest log loss score in comparison to the other classifiers, this does not give us an objective look into how the model is performing. <br>\n",
    "\n",
    "Let's take a look at the parameters that created this log loss score so we can isolate them and apply them to our testing dataset for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'feat_gen': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\\n        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\\n        lowercase=True, max_df=0.75, max_features=500, min_df=0.05,\\n        ngram_range=(2, 2), norm='l2', preprocessor=None, smooth_idf=True,\\n        stop_words=None, strip_accents=None, sublinear_tf=False,\\n        token_pattern='(?u)\\\\\\\\b\\\\\\\\w\\\\\\\\w+\\\\\\\\b', tokenizer=None, use_idf=True,\\n        vocabulary=None), 'feat_gen__max_df': 0.75, 'feat_gen__min_df': 0.05, 'machine': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\\n            max_depth=30, max_features='auto', max_leaf_nodes=None,\\n            min_impurity_decrease=0.0, min_impurity_split=None,\\n            min_samples_leaf=1, min_samples_split=430,\\n            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\\n            oob_score=False, random_state=1, verbose=0, warm_start=False), 'machine__max_depth': 30, 'machine__min_samples_split': 430, 'machine__n_estimators': 10, 'oversample__kind': 'regular'}\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random forest hyper-parameters\n",
    "best_gridresults['params'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Feature Generator: TfidfVectorizer\n",
    "- max_df = 0.75\n",
    "- max_features = 500\n",
    "- min_df = 0.05\n",
    "- ngram_range = (2,2)\n",
    "- oversample kind = regular\n",
    "- Classifier: RandomForestClassifier\n",
    "- max_depth = 30\n",
    "- min_samples_split = 430\n",
    "- n_estimators = 10\n",
    "\n",
    "It should come as no surprise that tf-idf is the better feature generator. Across the board, tf-idf performed better than bag-of-words. The max_df was on the upper range of the available values, and the min_df was in the middle. The model used bigrams instead of unigrams, which is interesting given the relatively small size of the corpus. Oversampling was helpful with the 'regular' method. Max_depth was the only hyper-parameter native to the random forest that was tuned, and it worked best on the lower range of what was available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation\n",
    "\n",
    "Let's see how this set of hyper-parameters performs on our external validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load in training dataframe\n",
    "train = pd.read_csv('~/tumor-mutation-classification/scripts/lemmatized_train.csv')\n",
    "X_train = train['lemmatized']\n",
    "Y_train = train['Class']\n",
    "test = pd.read_csv('~/tumor-mutation-classification/scripts/lemmatized_test.csv')\n",
    "X_test = test['lemmas']\n",
    "Y_test = test['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Re-usable function for evaluating performance of validation model\n",
    "def validate_score_pipeline (X_train, Y_train, X_test, Y_test, pipe):\n",
    "    \n",
    "    pipe.fit(X_train, Y_train)\n",
    "    Y_pred = pipe.predict(X_test)\n",
    "    Y_pred_prob = pipe.predict_proba(X_test)\n",
    "    \n",
    "    print('Log Loss: ', log_loss(Y_test, Y_pred_prob))\n",
    "    print('Accuracy: ', accuracy_score(Y_test, Y_pred))\n",
    "    print('\\nConfusion Matrix:\\n', confusion_matrix(Y_test, Y_pred))\n",
    "    print('\\nClassification Report:\\n', classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss:  1.71745463541\n",
      "Accuracy:  0.371428571429\n",
      "\n",
      "Confusion Matrix:\n",
      " [[30  5  2 14 16 18  3  7 12]\n",
      " [ 2 48  3  4  1  7 20 11  2]\n",
      " [ 3  3 11  2  1  1  1  0  0]\n",
      " [21  8  8 45 13 14  5  7 20]\n",
      " [ 5  1  4  4 20  7  3  0  1]\n",
      " [ 3  2  1  2  3 35  2  0  0]\n",
      " [14 55 28  7  8  5 50 13 12]\n",
      " [ 0  0  0  0  0  0  2  1  1]\n",
      " [ 0  0  0  0  0  0  1  0  7]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.38      0.28      0.32       107\n",
      "          2       0.39      0.49      0.44        98\n",
      "          3       0.19      0.50      0.28        22\n",
      "          4       0.58      0.32      0.41       141\n",
      "          5       0.32      0.44      0.37        45\n",
      "          6       0.40      0.73      0.52        48\n",
      "          7       0.57      0.26      0.36       192\n",
      "          8       0.03      0.25      0.05         4\n",
      "          9       0.13      0.88      0.22         8\n",
      "\n",
      "avg / total       0.47      0.37      0.38       665\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pipeline parameters reduced to best-performing parameters from prior grid search\n",
    "def random_forest_validation(X_train, Y_train, X_test, Y_test):\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('feat_gen', TfidfVectorizer(max_df = 0.75, min_df = 0.05, max_features = 500)),\n",
    "        ('oversample', SMOTE(k_neighbors = 5, kind = 'regular', random_state = 1)),\n",
    "        ('machine', RandomForestClassifier(max_depth = 30, min_samples_split = 430, n_estimators = 10, random_state = 1))\n",
    "    ])\n",
    "\n",
    "    validate_score_pipeline(X_train, Y_train, X_test, Y_test, pipe)\n",
    "    \n",
    "random_forest_validation(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running validation on our external dataset, we can see that we have a baseline of **1.72 log loss score** and **37% accuracy** with **0.38 f1-score** (combining precision and recall). \n",
    "\n",
    "# Fine tuning the Random Forest\n",
    "\n",
    "Let us now alter a few steps of the process and feed these altered dataframes into the training model to see if we can get it to perform any better. First, we will try increasing the number of features in the vectorizer. Currently, the model is trained with the 500 most common words, but the corpus includes 205,136 unique words. We will experiment with increasing the number of words considered for the feature generator. After we find a set a changes that improves the training log loss score, we will validate it again using the external validation dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Re-usable function for evaluating performande of training model\n",
    "def train_score_pipeline (X_train, Y_train, pipe):\n",
    "    pipe.fit(X_train, Y_train)\n",
    "    Y_pred = pipe.predict(X_train)\n",
    "    Y_pred_prob = pipe.predict_proba(X_train)\n",
    "\n",
    "    print('Log Loss: ', log_loss(Y_train, Y_pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss:  1.57133355091\n"
     ]
    }
   ],
   "source": [
    "# Retrying the random forest with 2000 most common words instead of 500\n",
    "pipe = Pipeline(steps=[\n",
    "    ('feat_gen', TfidfVectorizer(max_df = 0.75, min_df = 0.05, max_features = 2000)),\n",
    "    ('oversample', SMOTE(k_neighbors = 5, kind = 'regular', random_state = 1)),\n",
    "    ('machine', RandomForestClassifier(max_depth = 30, min_samples_split = 430, n_estimators = 10, random_state = 1))\n",
    "])\n",
    "\n",
    "train_score_pipeline(X_train, Y_train, pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the words in our vectorizer lowered the training log loss score from 1.83 to **1.57**. This is a change we will keep -- from now on, the max_features specified in the training model will be 2000. This also means that we will have to expand our testing documents to include include the 2000 common words instead of the original 500. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Conclusions: <br>\n",
    "Higher max features in vectorizer/vocabulary for testing documents. <br>\n",
    "**\n",
    "\n",
    "Now that we know that increasing the number of words considered in our vectorizer benefits our model, we can experiment with the number of words we choose. We will wrap this section of experimentation in a function for efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def change_max_features(X_train, Y_train, max_ft):\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('feat_gen', TfidfVectorizer(max_df = 0.75, min_df = 0.05, max_features = max_ft)),\n",
    "        ('oversample', SMOTE(k_neighbors = 5, kind = 'regular', random_state = 1)),\n",
    "        ('machine', RandomForestClassifier(max_depth = 30, min_samples_split = 430, n_estimators = 10, random_state = 1))\n",
    "    ])\n",
    "\n",
    "    train_score_pipeline(X_train, Y_train, pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss:  1.5337523908\n"
     ]
    }
   ],
   "source": [
    "change_max_features(X_train, Y_train, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss:  1.5337523908\n"
     ]
    }
   ],
   "source": [
    "change_max_features(X_train, Y_train, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss:  1.5337523908\n"
     ]
    }
   ],
   "source": [
    "change_max_features(X_train, Y_train, 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss:  1.5337523908\n"
     ]
    }
   ],
   "source": [
    "change_max_features(X_train, Y_train, 25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss:  1.5337523908\n"
     ]
    }
   ],
   "source": [
    "change_max_features(X_train, Y_train, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss:  1.5337523908\n"
     ]
    }
   ],
   "source": [
    "change_max_features(X_train, Y_train, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss:  1.57133355091\n"
     ]
    }
   ],
   "source": [
    "change_max_features(X_train, Y_train, 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After iterating through several values for how many word features to include in our vectorized dataframe, it appears that any number between 5000 words and all 2,000,000+ words yields the best log loss score at 1.53. We will move forward using 5000 words for simplicity's sake. At this time, we will reduce the vocabulary of the testing documents to 5000 words for our future validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Identifying 5000 most common words per training documents to reduce the vocabulary of the testing documents\n",
    "counter = Counter()\n",
    "\n",
    "for document in train['lemmatized']:\n",
    "    words = document.split(' ')\n",
    "    counter.update(words)\n",
    "\n",
    "word_frequencies = sorted(\n",
    "                        [[key, value] for key, value in counter.items()],\n",
    "                        key = lambda x: x[1],\n",
    "                        reverse = True\n",
    "                        )\n",
    "\n",
    "common_words_5000 = [frequency_pair[0] for frequency_pair in word_frequencies[:5000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating new test dataframe with 5000 most common words per training set\n",
    "test_5k = test.copy()\n",
    "reduced_documents_5000 = []\n",
    "\n",
    "for document in test['lemmatized'].values.tolist():\n",
    "    words = document.split(' ')\n",
    "    reduced_document = [word for word in words\n",
    "                       if word in common_words_5000]\n",
    "    reduced_document = ' '.join(reduced_document)\n",
    "    reduced_documents_5000.append(reduced_document)\n",
    "    \n",
    "test_5k['lemmatized'] = reduced_documents_5000\n",
    "\n",
    "# Exporting updated testing dataframe to csv for future reference\n",
    "test_5k.to_csv('lemmatized_test_5000.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 5000 words in our corpus, we will now re-run the grid search with more finely tuned parameters for the random forest model. This time, we will include a step for dimensionality reduction, which was neglected in the initial run of the grid searches. From 5000 initial features, the model will be given the option to reduce down to 1000, 500, and 100 components. Based on the best performing parameters from the initial random forest grid search, we are also  narrowing down the range of values for max_df and min_df in the word vectorizer, and max_depth and min_samples_split for the random forest. <br>\n",
    "Note: The grid search will be run in a script outside of this Jupyter notebook but the code will be pasted below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load in training dataframe\n",
    "train = pd.read_csv('~/tumor-mutation-classification/lemmatized_train.csv')\n",
    "X = train['lemmatized']\n",
    "Y = train['Class']\n",
    "\n",
    "# Set up pipeline\n",
    "pipe = Pipeline(steps=[\n",
    "    ('feat_gen', TfidfVectorizer()),\n",
    "    ('reduce_dim', decomposition.TruncatedSVD()),\n",
    "    ('oversample', SMOTE(k_neighbors = 5)),\n",
    "    ('machine', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Feature generation parameters\n",
    "maxdf = [0.65, 0.75, 0.85]\n",
    "mindf = [0.025, 0.05, .075]\n",
    "# Dimensionality reduction parameters\n",
    "n_components = [100, 500, 1000]\n",
    "# Oversampling parameters\n",
    "smote_kind = ['regular','borderline1']\n",
    "# Machine learning model parameters \n",
    "rf_max_depth = [20, 30, 40]\n",
    "rf_min_samples_split = [430, 860]\t# 430 represents 5% of the dataset after oversampling\n",
    "rf_n_estimators = [10]\n",
    "\n",
    "param_grid = [\n",
    "# Tfidf permutations with and without n-grams\n",
    "# Removed permutations with CountVectorizer after logistic regression demonstrated poor log loss scores\n",
    "# Removed permutations without oversampling after logistic regression demonstrated poor log loss scores\n",
    "    {\n",
    "        'feat_gen': [TfidfVectorizer(max_features = 5000)],\n",
    "        'feat_gen__max_df': maxdf,\n",
    "        'feat_gen__min_df': mindf,\n",
    "        'reduce_dim__n_components': n_components,\n",
    "        'oversample__kind': smote_kind,\n",
    "        'machine': [RandomForestClassifier(random_state = 1)],\n",
    "        'machine__max_depth': rf_max_depth,\n",
    "        'machine__min_samples_split': rf_min_samples_split,\n",
    "        'machine__n_estimators': rf_n_estimators\n",
    "    },\n",
    "        {\n",
    "        'feat_gen': [TfidfVectorizer(max_features = 5000, ngram_range=(2,2))],\n",
    "        'feat_gen__max_df': maxdf,\n",
    "        'feat_gen__min_df': mindf,\n",
    "        'reduce_dim__n_components': n_components,\n",
    "        'oversample__kind': smote_kind,\n",
    "        'machine': [RandomForestClassifier(random_state = 1)],\n",
    "        'machine__max_depth': rf_max_depth,\n",
    "        'machine__min_samples_split': rf_min_samples_split,\n",
    "        'machine__n_estimators': rf_n_estimators\n",
    "    }\n",
    "]\n",
    "# Run grid search with cross validation\n",
    "grid = GridSearchCVProgressBar(pipe, cv=3, param_grid=param_grid, verbose=2, scoring = 'log_loss')\n",
    "grid.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in results from the grid search run externally in a script..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                        random forest\n",
       "1                                              1.67208\n",
       "2                                            0.0287829\n",
       "3    {'feat_gen': TfidfVectorizer(analyzer='word', ...\n",
       "dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf2_results = pd.read_csv('scripts/rf2_gridresults_20180713_13:08.csv')\n",
    "best_rf2 = pd.Series(['random forest', rf2_results['mean'][0], rf2_results['std'][0], rf2_results['params'][0]])\n",
    "best_rf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'feat_gen': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\\n        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\\n        lowercase=True, max_df=0.65, max_features=5000, min_df=0.025,\\n        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\\n        stop_words=None, strip_accents=None, sublinear_tf=False,\\n        token_pattern='(?u)\\\\\\\\b\\\\\\\\w\\\\\\\\w+\\\\\\\\b', tokenizer=None, use_idf=True,\\n        vocabulary=None), 'feat_gen__max_df': 0.65, 'feat_gen__min_df': 0.025, 'machine': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\\n            max_depth=20, max_features='auto', max_leaf_nodes=None,\\n            min_impurity_decrease=0.0, min_impurity_split=None,\\n            min_samples_leaf=1, min_samples_split=430,\\n            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\\n            oob_score=False, random_state=1, verbose=0, warm_start=False), 'machine__max_depth': 20, 'machine__min_samples_split': 430, 'machine__n_estimators': 10, 'oversample__kind': 'regular', 'reduce_dim__n_components': 100}\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf2[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Feature Generator: TfidfVectorizer\n",
    "- max_df = 0.65\n",
    "- max_features = 5000\n",
    "- min_df = 0.025\n",
    "- ngram_range = (1,1)\n",
    "- oversample kind = regular\n",
    "- n_components = 100\n",
    "- Classifier: RandomForestClassifier\n",
    "- max_depth = 20\n",
    "- min_samples_split = 430\n",
    "- n_estimators = 10\n",
    "\n",
    "Now that we have identified the best performing parameters for our narrowed-down grid search, we can test them on our validation dataset. Our new set of parameters utilizes heavy dimensionality reduction, reducing from 5000 features to 100 components. Also, this model uses unigrams, possible because bigrams would not retain enough information with only 100 features. The max_df of the vectorizer went down, as did the max_depth of the random forest.<br>\n",
    "\n",
    "Let's run these hyperparameters on the testing dataset to see how this model generalizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading in training/testing dataframes\n",
      "Log Loss:  1.63802579801\n",
      "Accuracy:  0.406015037594\n",
      "\n",
      "Confusion Matrix:\n",
      " [[53  2  2 14 16  0  9  9  2]\n",
      " [10 40  6  6  0  2 22 12  0]\n",
      " [ 4  1 11  2  2  0  2  0  0]\n",
      " [48  0  4 56 17  1  6  9  0]\n",
      " [10  1 11  3 10  1  9  0  0]\n",
      " [11  0  1  2  9 17  7  1  0]\n",
      " [13 32 31 14  0  3 78 19  2]\n",
      " [ 0  0  0  1  0  0  1  2  0]\n",
      " [ 1  0  0  0  0  0  0  4  3]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.35      0.50      0.41       107\n",
      "          2       0.53      0.41      0.46        98\n",
      "          3       0.17      0.50      0.25        22\n",
      "          4       0.57      0.40      0.47       141\n",
      "          5       0.19      0.22      0.20        45\n",
      "          6       0.71      0.35      0.47        48\n",
      "          7       0.58      0.41      0.48       192\n",
      "          8       0.04      0.50      0.07         4\n",
      "          9       0.43      0.38      0.40         8\n",
      "\n",
      "avg / total       0.50      0.41      0.43       665\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load in training dataframe\n",
    "print(\"loading in training/testing dataframes\")\n",
    "train = pd.read_csv('~/tumor-mutation-classification/scripts/lemmatized_train.csv')\n",
    "X_train = train['lemmatized']\n",
    "Y_train = train['Class']\n",
    "test = pd.read_csv('~/tumor-mutation-classification/lemmatized_test_5000.csv')\n",
    "X_test = test['lemmas']\n",
    "Y_test = test['Class']\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    ('feat_gen', TfidfVectorizer(max_df = 0.65, min_df = 0.025, max_features = 5000, ngram_range = (1,1))),\n",
    "    ('oversample', SMOTE(k_neighbors = 5, kind = 'regular', random_state = 1)),\n",
    "    ('reduce_dim', decomposition.TruncatedSVD(n_components = 100)),\n",
    "    ('machine', RandomForestClassifier(max_depth = 20, min_samples_split = 430, n_estimators = 10, random_state = 1))\n",
    "])\n",
    "\n",
    "validate_score_pipeline(X_train, Y_train, X_test, Y_test, pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running a second grid search in which the hyper-parameters were tuned to narrow in on the best-performing parameters from earlier, we found a set of parameters that improved our validation log loss score from 1.72 to **1.64**. The accuracy also improved from 37% to 41%, and the f1-score improved from 0.38 to 0.43. While these are significant improvements, the accuracy remains less than 50%, indicating that this product is not satisfactory for professional use. We will now explore other methods of feature representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec\n",
    "\n",
    "So far, our methods of feature generation have been reliant on one-hot word vectors, which is a sparse representation with no information regarding the meaning or context of the word. We will now experiment with using Word2Vec, a package from Google that relies on distributed representation. Distributed representation means that each word is represented in several places, both as the \"center\" word of a phrase and as a \"context\" word for other words. The resulting word vectors are dense because they carry information about the surrounding words. This is how Word2Vec is able to retain information about word semantics and meaning. One implementation of Word2Vec is gensim's Doc2Vec, which uses the word vectors to create a document vector that determines document similarity.<br>\n",
    "\n",
    "Since Doc2Vec works on building concept, we will train the model using the lemmatized documents since they should help reduce some of noise to preserve the concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add tag to each document\n",
    "def tag_docs(df):\n",
    "    docs = []\n",
    "    for row in df.iterrows():\n",
    "        docs.append(TaggedDocument(words = simple_preprocess(row[1]['text']), tags=[row[1]['Class']]))\n",
    "        # simple preprocess converts a document into a list of tokens.\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train doc2vec model\n",
    "def train_doc2vec_model(tagged_docs, window, size):\n",
    "    sents = tagged_docs\n",
    "    doc2vec_model = Doc2Vec(sents, size=size, window=window, iter=20, dm=1)\n",
    "    return doc2vec_model\n",
    "\n",
    "# Other parameter options: min_count=5, workers=1, epochs=20\n",
    "# model.build_vocab(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build the final vector feature for the classifier\n",
    "def vec_for_learning(doc2vec_model, tagged_docs):\n",
    "    sents = tagged_docs\n",
    "    Y, X = zip(*[(doc.tags[0], doc2vec_model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return Y, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/gensim/models/doc2vec.py:362: UserWarning: The parameter `iter` is deprecated, will be removed in 4.0.0, use `epochs` instead.\n",
      "  warnings.warn(\"The parameter `iter` is deprecated, will be removed in 4.0.0, use `epochs` instead.\")\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/gensim/models/doc2vec.py:366: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('~/tumor-mutation-classification/lemmatized_train.csv')\n",
    "test = pd.read_csv('~/tumor-mutation-classification/lemmatized_test_full.csv')\n",
    "\n",
    "train_tagged = tag_docs(train)\n",
    "test_tagged = tag_docs(test)\n",
    "model = train_doc2vec_model(train_tagged, 5, 300)\n",
    "\n",
    "y_train, X_train = vec_for_learning(model, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model, test_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Export vectorized dataframes\n",
    "X_train_np = np.asarray(X_train)\n",
    "y_train_np = np.asarray(y_train)\n",
    "X_test_np = np.asarray(X_test)\n",
    "y_test_np = np.asarray(y_test)\n",
    "\n",
    "np.savetxt(\"d2v_X_train.csv\", X_train_np, delimiter=\",\")\n",
    "np.savetxt(\"d2v_y_train.csv\", y_train_np, delimiter=\",\")\n",
    "np.savetxt(\"d2v_X_test.csv\", X_test_np, delimiter=\",\")\n",
    "np.savetxt(\"d2v_y_test.csv\", y_test_np, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our preprocessed dataframes exported and ready, we can feed them into our classifiers to get a basic picture of how they perform. We will run them through various external grid searches to determine the best hyperparameters to feed into our machine learning models and subsequently validate them below. Naive Bayes cannot be run here because Doc2Vec uses directionality to retain contextual information about the words, which results in negative values that Naive Bayes cannot handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      classifier      mean       std  \\\n",
      "0       logistic  0.786146  0.037976   \n",
      "2        xgboost  0.885314  0.051294   \n",
      "1  random forest  1.429836  0.032435   \n",
      "\n",
      "                                              params  \n",
      "0  {'machine': LogisticRegression(C=0.1, class_we...  \n",
      "2  {'machine': XGBClassifier(base_score=0.5, boos...  \n",
      "1  {'machine': RandomForestClassifier(bootstrap=T...  \n"
     ]
    }
   ],
   "source": [
    "d2v_logistic_results = pd.read_csv('scripts/d2v_logistic_results_20180730_18:43.csv')\n",
    "d2v_rf_results = pd.read_csv('scripts/d2v_rf_gridresults_20180730_18:39.csv')\n",
    "d2v_xg_results = pd.read_csv('scripts/d2v_xg_gridresults_20180730_05:53.csv')\n",
    "\n",
    "best_logistic = pd.Series(['logistic', d2v_logistic_results['mean'][0], d2v_logistic_results['std'][0], d2v_logistic_results['params'][0]])\n",
    "best_rf = pd.Series(['random forest', d2v_rf_results['mean'][0], d2v_rf_results['std'][0], d2v_rf_results['params'][0]])\n",
    "best_xg = pd.Series(['xgboost', d2v_xg_results['mean'][0], d2v_xg_results['std'][0], d2v_xg_results['params'][0]])\n",
    "best_gridresults = pd.DataFrame().append([best_logistic, best_rf, best_xg], ignore_index=True)\n",
    "best_gridresults.columns = ['classifier','mean','std','params']\n",
    "best_gridresults = best_gridresults.sort_values(by=['mean'], ascending=True)\n",
    "print(best_gridresults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance, it appears that using a Doc2Vec feature representation is highly beneficial to our log loss score. The logistic regression model performed best here, while the random forest performed best in the first round of grid searches. Let's confirm this on our validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('~/tumor-mutation-classification/scripts/d2v_X_train.csv')\n",
    "X_test = pd.read_csv('~/tumor-mutation-classification/scripts/d2v_X_test.csv')\n",
    "y_train = pd.read_csv('~/tumor-mutation-classification/scripts/d2v_y_train.csv')\n",
    "y_test = pd.read_csv('~/tumor-mutation-classification/scripts/d2v_y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'machine': LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), 'machine__C': 0.1, 'reduce_dim__n_components': 50}\n"
     ]
    }
   ],
   "source": [
    "print(best_gridresults['params'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss:  1.62093207631\n",
      "Accuracy:  0.573795180723\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 51   3   0  23  13   5  10   1   0]\n",
      " [  6  43   1   5   1   2  38   1   1]\n",
      " [  1   0  10   5   3   1   2   0   0]\n",
      " [ 29   3   5  83  14   3   3   1   0]\n",
      " [  5   0   1   3  24   6   6   0   0]\n",
      " [  5   4   1   0   5  29   4   0   0]\n",
      " [  6  27   9   2  14   2 132   0   0]\n",
      " [  0   1   0   0   0   0   1   2   0]\n",
      " [  0   0   0   0   0   0   0   1   7]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.50      0.48      0.49       106\n",
      "        2.0       0.53      0.44      0.48        98\n",
      "        3.0       0.37      0.45      0.41        22\n",
      "        4.0       0.69      0.59      0.63       141\n",
      "        5.0       0.32      0.53      0.40        45\n",
      "        6.0       0.60      0.60      0.60        48\n",
      "        7.0       0.67      0.69      0.68       192\n",
      "        8.0       0.33      0.50      0.40         4\n",
      "        9.0       0.88      0.88      0.88         8\n",
      "\n",
      "avg / total       0.59      0.57      0.58       664\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameters reduced to best-performing parameters from prior grid search\n",
    "def logistic_validation(X_train, Y_train, X_test, Y_test):\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('reduce_dim', decomposition.TruncatedSVD(n_components = 50)),\n",
    "        ('oversample', SMOTE(k_neighbors = 5, kind = 'regular', random_state = 1)),\n",
    "        ('machine', LogisticRegression(C = 0.1, penalty = 'l2', random_state = 1))\n",
    "    ])\n",
    "\n",
    "    validate_score_pipeline(X_train, Y_train, X_test, Y_test, pipe)\n",
    "    \n",
    "logistic_validation(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a log loss score of **1.63**, this method of feature representation performs slightly better than tf-idf vectorization, which had a validated log loss score of 1.64. However, when compared to the training log loss score of 0.79, we can see that this model is dramatically overfitting. The f1-score went up to 0.58 (compared to 0.43 with tf-idf and random forest) but the f1-score is less meaningful than the log loss score because it doesn't reflect the model's confidence in its predictions. Any accuracy gained in the f1-score is likely the result of chance, while an improvement in the log loss score indicates that the model was more confident in its correct predictions (or less confident in its wrong ones). However, since the improvement is so minor and implicated with overfitting, we will not move forward with this model. <br>\n",
    "\n",
    "Let's try the second best-performing classifier XGBoost to see if we can observe less overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'machine': XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=100, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=0.5), 'machine__booster': 'gbtree', 'machine__learning_rate': 0.1, 'machine__max_depth': 100, 'machine__subsample': 0.5, 'oversample__kind': 'borderline1', 'reduce_dim__n_components': 50}\n"
     ]
    }
   ],
   "source": [
    "print(best_gridresults['params'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss:  1.5352258066\n",
      "Accuracy:  0.605421686747\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 53   4   0  24  11   3  10   0   1]\n",
      " [  3  41   0   4   1   4  45   0   0]\n",
      " [  2   0  10   6   1   1   2   0   0]\n",
      " [ 29   2   2  93   9   3   2   1   0]\n",
      " [  8   1   1   5  20   4   6   0   0]\n",
      " [  7   5   1   0   2  31   2   0   0]\n",
      " [  3  24   5   2  10   2 145   0   1]\n",
      " [  0   1   0   0   0   0   1   2   0]\n",
      " [  0   0   0   0   0   0   0   1   7]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.50      0.50      0.50       106\n",
      "        2.0       0.53      0.42      0.47        98\n",
      "        3.0       0.53      0.45      0.49        22\n",
      "        4.0       0.69      0.66      0.68       141\n",
      "        5.0       0.37      0.44      0.40        45\n",
      "        6.0       0.65      0.65      0.65        48\n",
      "        7.0       0.68      0.76      0.72       192\n",
      "        8.0       0.50      0.50      0.50         4\n",
      "        9.0       0.78      0.88      0.82         8\n",
      "\n",
      "avg / total       0.60      0.61      0.60       664\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set up pipeline\n",
    "# Parameters reduced to best-performing parameters from prior grid search\n",
    "def xgboost_validation(X_train, Y_train, X_test, Y_test):\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('reduce_dim', decomposition.TruncatedSVD(n_components = 50)),\n",
    "        ('oversample', SMOTE(k_neighbors = 5, kind = 'regular', random_state = 1)),\n",
    "        ('machine', XGBClassifier(booster = 'gbtree',learning_rate = 0.1, max_depth = 100, subsample = 0.5, random_state = 1))\n",
    "    ])\n",
    "\n",
    "    validate_score_pipeline(X_train, Y_train, X_test, Y_test, pipe)\n",
    "    \n",
    "xgboost_validation(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a log loss score of **1.53**, this is significantly better than the logistic regression model, but is still overfitting dramatically. So far, this Doc2Vec model is our best model, but not by much. That said, we only tried one combination of hyper-parameters for 'window' and 'size', and there are others we neglected to tune as well. With the time and space to try more combinations, it is possible that this model could improve its performance by much more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "At this point, we have tried several methods of NLP feature representation for this text dataset. What started as a list of peer-reviewed journal articles became a matrix of numbers and one-hot vectors as we experimented with tf-idf and bag-of-words vectorization. Unfortunately, neither were sufficient to classify our test documents into their rightful classes. <br>\n",
    "\n",
    "In our first round of feature engineering, we created a pipeline to test several different hyperparameters to tune the vectorization process and ran each resulting dataframe through a grid search to determine the best machine learning model parameters. Logistic regression, random forest, XGBoost, and Naive Bayes were implemented; of these models, random forest performed the best with our tf-idf vectorized dataset. After some more fine tuning of the feature generation/machine learning model, we were able to come up with a log loss score of 1.64. This involved using tf-idf vectorization and reducing our feature set down to our 5000 most common words (after filtering out stopwords and lemmatizing). One potential issue here is that the 5000 most common words may not actually be our best features, but we reduced the dataset to these words for the sake of computational and conceptual simplicity. <br>\n",
    "\n",
    "It became clear that tf-idf and bag-of-words vectorization were not performing well through inspection of the f1-score, a reflection of both precision and recall. Although log loss is the objective scoring measure we are using to judge our models against eachother, there is no standard way of interpreting a lone log loss score. For more interpretability we looked into the f1-score, conveniently ranked between 0 and 1. The best model we could ascertain had an f1-score of 0.43, with average precision at 0.50 and recall at 0.41. This is a poor classifier for our models, as only half of its positive predictions are correct. <br>\n",
    "\n",
    "This led us to seek out a more nuanced method of feature representation. I chose the Doc2Vec feature of Google's Word2Vec for its ability to incorporate semantics and concepts into the word vectors. With only one iteration of hyperparameters for training the Doc2Vec model, we re-ran all of our machine learning classifiers and found that XGBoost was the best way to model this feature set. The log loss score improved from 1.64 to 1.53, and the F1-score improved significantly from 0.43 to 0.60. This indicates that a small improvement in our accuracy as well as higher confidence in its correct predictions. <br>\n",
    "\n",
    "For the sake of brevity we did not optimize the hyperparameters for the Doc2Vec model the same way that we did for the first round of feature engineering, though this is certainly something we could explore further in the future. However, our model will only ever be as good as the data we give it, and this may be our biggest limitation. NLP projects tend to work best when distinguishing categories or writing styles, but since we are working with a body of technical writing, much of the structure and vocabulary remains consistent across the board. Technical writing abides by certain guidelines of how sentences are meant to be formed and there is little room left for personal touch or artistic interpretation. <br>\n",
    "\n",
    "Additionally, the severe class imbalance is likely not helping our models. We found through cross-validation that oversampling is indeed beneficial for this dataset, especially when paired with significant dimensionality reduction, but these two techniques together are still not enough to save the model's overall performance. More data (especially in the minority classes) would certainly help our case, but if the style of technical writing remains so cut-and-dried it may give credence to the notion that this dataset is not suitable for a supervised learning model.<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
